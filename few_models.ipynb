{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Tuning Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Problem\n",
    "\n",
    "When we predict a catgorical target, we have a classification problem.  We will use the `titanic` dataset as an example for implementing a several classifers in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Assign input variables\n",
    "X = df.loc[:,['Pclass','Sex','Age','Fare','Embarked','SibSp','Parch']]\n",
    "\n",
    "# Assign target variable\n",
    "y = df['Survived']\n",
    "\n",
    "# Replace missing values by the median\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "\n",
    "# Impute the Embarked variable\n",
    "X[\"Embarked\"] = X[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Pclass to categorical variable\n",
    "X['Pclass'] = X['Pclass'].astype(object)\n",
    "\n",
    "# Encode categorical variable\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9803370786516854\n",
      "Testing Accuracy: 0.7486033519553073\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree and train\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'criterion': 'gini', 'max_depth': 6}\n",
      "Training Accuracy: 0.8820224719101124\n",
      "Testing Accuracy: 0.770949720670391\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'max_depth': range(1,10), 'criterion':['gini', 'entropy']}\n",
    "\n",
    "# Create a list of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8384831460674157\n",
      "Testing Accuracy: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.112, 'n_estimators': 75}\n",
      "Training Accuracy: 0.824438202247191\n",
      "Testing Accuracy: 0.770949720670391\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1,100, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(AdaBoostClassifier(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9129213483146067\n",
      "Testing Accuracy: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.445, 'n_estimators': 5}\n",
      "Training Accuracy: 0.8539325842696629\n",
      "Testing Accuracy: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1,50, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(GradientBoostingClassifier(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9676966292134831\n",
      "Testing Accuracy: 0.770949720670391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_features': 9, 'n_estimators': 28}\n",
      "Training Accuracy: 0.9789325842696629\n",
      "Testing Accuracy: 0.7932960893854749\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(2,50, 2), 'max_features':np.arange(2,10)}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(RandomForestClassifier(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8216292134831461\n",
      "Testing Accuracy: 0.7318435754189944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'n_neighbors': 2}\n",
      "Training Accuracy: 0.8356741573033708\n",
      "Testing Accuracy: 0.6815642458100558\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_neighbors': np.arange(2,20, 2)}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(KNeighborsClassifier(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet\n",
    "\n",
    "Notice that ElasticNet model includes LASSO, Ridge Regression and Logistic Regression.  Change the value of `alpha` and `l1_ratio` to have the desired model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6671348314606742\n",
      "Testing Accuracy: 0.6480446927374302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(loss='log', penalty='elasticnet', alpha=1, l1_ratio=.1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elasticnet Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'alpha': 0.1, 'l1_ratio': 0.0}\n",
      "Training Accuracy: 0.6615168539325843\n",
      "Testing Accuracy: 0.6312849162011173\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'alpha':np.linspace(0.1,10, 10), 'l1_ratio':np.linspace(0,1,10)}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7991573033707865\n",
      "Testing Accuracy: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "# Accuracry on training data\n",
    "print('Training Accuracy:', model.score(x_train, y_train))\n",
    "\n",
    "# Prediction and accuracy on testing data\n",
    "y_pred = model.predict(x_test)\n",
    "print('Testing Accuracy:', metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Problem\n",
    "\n",
    "When we predict a numeric target, we have a regression problem.  We will use the `boston housing` dataset as an example for implementing a several regressors in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston=load_boston()\n",
    "boston_df=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "\n",
    "#print boston_df.info()\n",
    "# add another column that contains the house prices which in scikit learn datasets are considered as target\n",
    "boston_df['Price']=boston.target\n",
    "\n",
    "#print boston_df.head(3)\n",
    "newX=boston_df.drop('Price',axis=1)\n",
    "newY=boston_df['Price']\n",
    "#print type(newY)# pandas core frame\n",
    "x_train,x_test,y_train,y_test=train_test_split(newX,newY,test_size=0.3,random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 1.0\n",
      "Rsquared on Testing 0.6275316392243291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Create a decision tree and train\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_depth': 46}\n",
      "Rsquared on Training 1.0\n",
      "Rsquared on Testing 0.6983656152467781\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'max_depth': np.arange(1,100,5)}\n",
    "\n",
    "# Create a list of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.9092212616586101\n",
      "Rsquared on Testing 0.849114176702914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create a decision tree and train\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.445, 'n_estimators': 31}\n",
      "Rsquared on Training 0.8941910447449928\n",
      "Rsquared on Testing 0.8006519125223412\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1,100, 2), 'learning_rate':np.linspace(0.001,1,10)}\n",
    "\n",
    "# Create a list of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(AdaBoostRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.9617639347910545\n",
      "Rsquared on Testing 0.7958895500037099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Create a decision tree and train\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_features': 5, 'n_estimators': 26}\n",
      "Rsquared on Training 0.9786420237922232\n",
      "Rsquared on Testing 0.8826499273162934\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(2,50, 2), 'max_features':np.arange(2,10)}\n",
    "\n",
    "# Create a list of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.9818535458511707\n",
      "Rsquared on Testing 0.8857026030279465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create a decision tree and train\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'learning_rate': 0.223, 'n_estimators': 19}\n",
      "Rsquared on Training 0.9575133653372899\n",
      "Rsquared on Testing 0.8572693411649928\n"
     ]
    }
   ],
   "source": [
    "# Decide what hyperparameter to tune then decide the searching range\n",
    "param_grid = {'n_estimators': np.arange(1,20, 2), 'learning_rate':np.linspace(0.001,.3,10)}\n",
    "\n",
    "# Create a list of trees\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = GridSearchCV(GradientBoostingRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.6669924636401611\n",
      "Rsquared on Testing 0.7041261455492028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'alpha': 0.0, 'l1_ratio': 0.0}\n",
      "Rsquared on Training 0.7176202687340321\n",
      "Rsquared on Testing 0.7826126074271011\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha':np.linspace(0,10, 10), 'l1_ratio':np.linspace(0,1,10)}\n",
    "model = GridSearchCV(ElasticNet(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared on Training 0.6680284285778176\n",
      "Rsquared on Testing 0.5941848521354716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'n_neighbors': 3}\n",
      "Rsquared on Training 0.7561816517830935\n",
      "Rsquared on Testing 0.5547519590174173\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors':np.arange(1,10)}\n",
    "model = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best found paramters\n",
    "print('Best parameters are:', model.best_params_)\n",
    "\n",
    "# Print the Rsquared on training and testing\n",
    "print('Rsquared on Training', r2_score(y_train, model.predict(x_train)))\n",
    "print('Rsquared on Testing', r2_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
